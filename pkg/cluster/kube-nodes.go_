package bus

import (
	"context"
	"encoding/json"
	"fmt"
	"net"
	"net/url"
	"os"
	"sort"
	"sync"
	"time"

	"github.com/nats-io/nats-server/v2/server"
	"github.com/nats-io/nats.go"
	apiv1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/watch"
	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/rest"
)

const (
	direktivKubernetesPodLabel = "app.kubernetes.io/name=direktiv"

	requestWaitTime = 10
)

func flowNodes(b *Bus) ([]*url.URL, error) {
	nodes := make([]*url.URL, 0)

	clientset, err := getClientSet()
	if err != nil {
		return nodes, err
	}

	deployments, err := clientset.AppsV1().Deployments(envDirektivNamespace).Get(context.Background(),
		fmt.Sprintf("%s-flow", envDirektivDeployment), metav1.GetOptions{})
	if err != nil {
		return nodes, err
	}

	replicas := int(*deployments.Spec.Replicas)

	b.Logger.Infof("flow replicas found: %d", replicas)

	b.isClustered = true

	// single node cluster
	if replicas == 1 {
		b.isClustered = false

		return nodes, nil
	}

	var pods *apiv1.PodList

	b.Logger.Infof("fetching replicas: %d", replicas)

	for {
		pods, err = clientset.CoreV1().Pods(envDirektivNamespace).List(context.Background(), metav1.ListOptions{
			LabelSelector: direktivKubernetesPodLabel,
			FieldSelector: "status.phase=Running",
		})
		if err != nil {
			return nodes, err
		}

		if len(pods.Items) == replicas {
			break
		}
		time.Sleep(1 * time.Second)
	}

	for i := range pods.Items {
		// err = waitForPodIP(&pods.Items[i])
		// if err != nil {
		// 	b.Logger.Errorf("%s", err.Error())
		// 	os.Exit(1)
		// }

		parsedNode, err := url.Parse(fmt.Sprintf("nats://%s", net.JoinHostPort(pods.Items[i].Status.PodIP,
			fmt.Sprintf("%d", direktivNATSClusterPort))))
		if err != nil {
			return nil, err
		}
		b.Logger.Debugf("fetched replica %d: %v", i, parsedNode)
		nodes = append(nodes, parsedNode)
	}

	b.Logger.Debugf("fetched replicas: %v", nodes)

	return server.RemoveSelfReference(direktivNATSClusterPort, nodes)

}

func NodeFinderKubernetes(b *Bus) ([]*url.URL, error) {
	nodes, err := flowNodes(b)
	if err != nil {
		return nil, err
	}

	go consolidate(b)

	go startInformer(b)

	return nodes, nil
}

func idxForNode(urls []*url.URL, pod *apiv1.Pod) int {

	idx := -1

	for i := range urls {
		r := urls[i]
		if r != nil && r.Host == fmt.Sprintf("%s:%d", pod.Status.PodIP, direktivNATSClusterPort) {
			idx = i

			break
		}
	}

	return idx
}

func waitForPodIP(pod *apiv1.Pod) (string, error) {
	// if ip had been assigned already
	if pod.Status.PodIP != "" {
		return pod.Status.PodIP, nil
	}

	cs, err := getClientSet()
	if err != nil {
		return "", err
	}

	// waiting for 10 seconds to get an ip
	for i := 0; i < 10; i++ {
		p, err := cs.CoreV1().Pods(envDirektivNamespace).Get(context.Background(),
			pod.Name, metav1.GetOptions{})

		if err != nil || p.Status.PodIP == "" {
			time.Sleep(time.Second)

			continue
		}

		return p.Status.PodIP, nil
	}

	return "", fmt.Errorf("pod %s did not get an IP", pod.Name)

}

func addNodeToCluster(bus *Bus, pod *apiv1.Pod) error {

	// don't handle myself
	if bus.hostname == pod.Name {
		bus.Logger.Infof("skipping handling self-node")

		return nil
	}

	routesCopy := make([]*url.URL, 0)
	routesCopy = append(routesCopy, bus.options.Routes...)

	bus.Logger.Infof("adding pod %s to bus cluster", pod.Name)

	ip, err := waitForPodIP(pod)
	if err != nil {
		return err
	}

	parsedNode, err := url.Parse(fmt.Sprintf("nats://%s", net.JoinHostPort(ip,
		fmt.Sprintf("%d", direktivNATSClusterPort))))
	if err != nil {
		return err
	}

	// remove from config
	idx := idxForNode(routesCopy, pod)

	// only add it if it is not already there
	if idx == -1 {
		routesCopy = append(routesCopy, parsedNode)
		err = bus.setBusRoutes(routesCopy)
		if err != nil {
			return err
		}
	}

	return nil
}

func removeNodeFromCluster(bus *Bus, pod *apiv1.Pod) error {
	removeFromSlice := func(slice []*url.URL, s int) []*url.URL {
		return append(slice[:s], slice[s+1:]...)
	}

	routesCopy := make([]*url.URL, len(bus.options.Routes))
	copy(routesCopy, bus.options.Routes)

	err := bus.deleteStreamNode(pod.Name)
	if err != nil {
		return err
	}

	idx := idxForNode(routesCopy, pod)

	// remove from configuration if found
	if idx > -1 {
		routesCopy = removeFromSlice(routesCopy, idx)
		err = bus.setBusRoutes(routesCopy)
		if err != nil {
			return err
		}
	}

	return nil
}

func getClientSet() (*kubernetes.Clientset, error) {
	config, err := rest.InClusterConfig()
	if err != nil {
		return nil, err
	}

	return kubernetes.NewForConfig(config)
}

func startInformer(bus *Bus) {
	bus.startupWg.Wait()
	if true {
		return
	}

	clientset, err := getClientSet()
	if err != nil {
		bus.Logger.Errorf("error starting informer: %s", err.Error())
		os.Exit(1)
	}

	watcher, err := clientset.CoreV1().Pods(envDirektivNamespace).Watch(context.TODO(), metav1.ListOptions{
		LabelSelector: direktivKubernetesPodLabel,
	})

	// if we can not create a watcher we kill the pod
	if err != nil {
		bus.Logger.Errorf("error creating watcher: %v", err)
		os.Exit(1)
	}

	eventChan := watcher.ResultChan()
	var wg sync.WaitGroup
	wg.Add(1)

	go func() {
		defer wg.Done()

		for event := range eventChan {
			switch event.Type {
			case watch.Deleted:
				pod, ok := event.Object.(*apiv1.Pod)
				if ok {
					err = removeNodeFromCluster(bus, pod)
					if err != nil {
						bus.Logger.Errorf("can not delete bus node from cluster: %s", err.Error())

						continue
					}
				}
			case watch.Added:
				pod, ok := event.Object.(*apiv1.Pod)
				if ok {
					err = addNodeToCluster(bus, pod)
					if err != nil {
						bus.Logger.Errorf("can not add bus node to cluster: %s", err.Error())

						continue
					}
				}
			case watch.Modified:
			case watch.Bookmark:
			case watch.Error:
				err, ok := event.Object.(*metav1.Status)
				if ok {
					bus.Logger.Errorf("error watching pods: %v", err.Message)
					os.Exit(1)
				}
			}
		}
	}()

	wg.Wait()

}

func consolidate(b *Bus) {
	b.startupWg.Wait()

	for {
		time.Sleep(1 * time.Second)

		newNodes, err := flowNodes(b)
		if err != nil {
			b.Logger.Errorf("can not fetch nodes: %s", err.Error())
			os.Exit(1)
		}

		// if routes are the same in bu struct and realtime we can skip
		if arraysOfURLsAreEqual(newNodes, b.options.Routes) {
			continue
		}

		b.Logger.Infof("bus cluster has changed")

		urls := make(map[*url.URL]bool)

		// we store the existing routes and mark them as invalid
		for i := range b.options.Routes {
			urls[b.options.Routes[i]] = false
		}

		// overwrite the new ones
		for i := range newNodes {
			urls[newNodes[i]] = true
		}

		b.Logger.Debugf("route values: %v", urls)

		newRoutes := make([]*url.URL, 0)
		for k, v := range urls {
			if !v {
				err = b.deleteStreamNode(k.Host)
				if err != nil {
					b.Logger.Errorf("can not delete bus node: %s", err.Error())
				}
			} else {
				newRoutes = append(newRoutes, k)
			}
		}

		err = b.setBusRoutes(newRoutes)
		if err != nil {
			b.Logger.Errorf("can not reload bus options: %s", err.Error())
			os.Exit(1)
		}
	}

}

func (b *Bus) deleteStreamNode(pod string) error {
	b.Logger.Infof("removing node from bus cluster %v", pod)

	b.server.ReadyForConnections(30 * time.Second)

	opts := nats.GetDefaultOptions()
	opts.Url = natsLocal
	opts.AllowReconnect = true

	// maybe there is a leadership change
	opts.MaxReconnect = 30
	opts.ReconnectWait = time.Second
	opts.User = direktivNATSUser
	opts.Password = envDirektivNatsPwd
	opts.Timeout = 30 * time.Second

	nc, err := opts.Connect()
	if err != nil {
		return err
	}
	defer nc.Close()

	b.Logger.Infof("nats connected for removal of node %v", pod)

	req := &server.JSApiMetaServerRemoveRequest{Server: pod}
	jsreq, err := json.Marshal(req)
	if err != nil {
		return err
	}
	rmsg, err := nc.Request(server.JSApiRemoveServer, jsreq, requestWaitTime*time.Second)
	if err != nil {
		return err
	}
	var resp server.JSApiMetaServerRemoveResponse
	if err := json.Unmarshal(rmsg.Data, &resp); err != nil {
		return err
	}
	if resp.Error == nil {
		b.Logger.Errorf("failed to remove pod pod %s from bus cluster", pod)
		return err
	}

	b.Logger.Infof("pod %s removed from bus cluster", pod)

	return nil

}

func arraysOfURLsAreEqual(arr1, arr2 []*url.URL) bool {
	urlsAreEqual := func(u1, u2 *url.URL) bool {
		if u1.Scheme != u2.Scheme || u1.Host != u2.Host || u1.Path != u2.Path {
			return false
		}

		if u1.Fragment != u2.Fragment {
			return false
		}

		return true
	}

	if len(arr1) != len(arr2) {
		return false
	}

	sort.Slice(arr1, func(i, j int) bool {
		return arr1[i].String() < arr1[j].String()
	})
	sort.Slice(arr2, func(i, j int) bool {
		return arr2[i].String() < arr2[j].String()
	})

	for i := 0; i < len(arr1); i++ {
		if !urlsAreEqual(arr1[i], arr2[i]) {
			return false
		}
	}

	return true
}
